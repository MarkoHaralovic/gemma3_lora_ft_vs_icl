{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd4d78-f62c-4f05-aa56-2c205fa13a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# note this: set them when running\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "num_gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d49d53-45cb-4501-9739-0a65565e4981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from peft import PeftModel, PeftConfig\n",
    "from unsloth.chat_templates import get_chat_template \n",
    "import lm_eval\n",
    "from lm_eval import evaluator, tasks\n",
    "from lm_eval.utils import setup_logging\n",
    "import tempfile\n",
    "setup_logging(\"INFO\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4fdb9-9389-4cf9-bfd6-4b417a566c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_270m_pt_args = (\n",
    "    \"pretrained=google/gemma-3-270m,\"\n",
    "    \"tokenizer=google/gemma-3-270m,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_270m_it_args = (\n",
    "    \"pretrained=google/gemma-3-270m-it,\"\n",
    "    \"tokenizer=google/gemma-3-270m-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_1b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-1b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-1b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_1b_it_args = (\n",
    "    \"pretrained=google/gemma-3-1b-it,\"\n",
    "    \"tokenizer=google/gemma-3-1b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_4b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-4b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-4b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_4b_it_args = (\n",
    "    \"pretrained=google/gemma-3-4b-it,\"\n",
    "    \"tokenizer=google/gemma-3-4b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    ")\n",
    "\n",
    "gemma3_12b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-12b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-12b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    "    \"load_in_4bit=True,\"\n",
    "    \"bnb_4bit_quant_type=nf4,\"\n",
    "    \"bnb_4bit_compute_dtype=bfloat16\"\n",
    ")\n",
    "\n",
    "gemma3_12b_it_args = (\n",
    "    \"pretrained=google/gemma-3-12b-it,\"\n",
    "    \"tokenizer=google/gemma-3-12b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    "    \"load_in_4bit=True,\"\n",
    "    \"bnb_4bit_quant_type=nf4,\"\n",
    "    \"bnb_4bit_compute_dtype=bfloat16\"\n",
    ")\n",
    "\n",
    "gemma3_27b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-27b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-27b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True,\"\n",
    "    \"load_in_4bit=True,\"\n",
    "    \"bnb_4bit_quant_type=nf4,\"\n",
    "    \"bnb_4bit_compute_dtype=bfloat16\"\n",
    ")\n",
    "\n",
    "gemma3_27b_it_args = (\n",
    "    \"pretrained=google/gemma-3-27b-it,\"\n",
    "    \"tokenizer=google/gemma-3-27b-it,\"\n",
    "    \"dtype=bfloat16,\" \n",
    "    \"trust_remote_code=True,\"\n",
    "    \"load_in_4bit=True,\"\n",
    "    \"bnb_4bit_quant_type=nf4,\"\n",
    "    \"bnb_4bit_compute_dtype=bfloat16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472788c4-842d-4c4a-947e-846db64ff916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma3_models_full = {\n",
    "    \"google/gemma-3-270m-pt\" : gemma3_270m_pt_args,\n",
    "    \"google/gemma-3-270m-it\" : gemma3_270m_it_args,\n",
    "    \"google/gemma-3-1b-pt\" : gemma3_1b_pt_args,   \n",
    "    \"google/gemma-3-1b-it\" : gemma3_1b_it_args,   \n",
    "    \"google/gemma-3-4b-pt\" : gemma3_4b_pt_args,\n",
    "    \"google/gemma-3-4b-it\" : gemma3_4b_it_args,\n",
    "    \"google/gemma-3-12b-pt\" : gemma3_12b_pt_args,\n",
    "    \"google/gemma-3-12b-it\" : gemma3_12b_it_args,\n",
    "    \"google/gemma-3-27b-pt\" : gemma3_27b_pt_args,\n",
    "    \"google/gemma-3-27b-it\" : gemma3_27b_it_args\n",
    "}\n",
    "\n",
    "gemma3_models = {\n",
    "    \"google/gemma-3-270m-pt\" : gemma3_270m_pt_args,\n",
    "    \"google/gemma-3-270m-it\" : gemma3_270m_it_args\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4b6ae-201a-4d55-9800-ee66547045c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO add adapters evaluation\n",
    "gemma3_lora_adapters  = {\n",
    "    \"google/gemma-3-270m-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-270m-it_ft_ag_news\",\n",
    "        \"qa\" : \"Mhara/google_gemma-3-270m-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-1b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-1b-it_ft_ag_news\",\n",
    "        \"qa\" : \"Mhara/google_gemma-3-1b-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-4b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-4b-it_ft_ag_news\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-12b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-27b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "} \n",
    "\n",
    "def load_adapter(base_model_id, adapter_id):\n",
    "    cfg = PeftConfig.from_pretrained(adapter_id)\n",
    "    base_id = cfg.base_model_name_or_path or base_model_id\n",
    "\n",
    "    _tok = AutoTokenizer.from_pretrained(base_id, use_fast=True, trust_remote_code=True)\n",
    "    base = AutoModelForCausalLM.from_pretrained(\n",
    "        base_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    _model = PeftModel.from_pretrained(base, adapter_id)\n",
    "    _model.eval()\n",
    "    tok = get_chat_template(_tok, chat_template=\"gemma3\")\n",
    "\n",
    "    return _model, _tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e4a8a-1e9b-4df1-89ca-d8f0ff26267e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_to_evaluate_on = {\n",
    "    \"question_answering\"  : [\n",
    "        \"squadv2\", # SQuAD \n",
    "        \"triviaqa\", \n",
    "        \"nq_open\", # natural queustions testing long context evaluation\n",
    "        \"boolq\", #boolq\n",
    "        \"social_iqa\", # social  QA \n",
    "    ],\n",
    "    \"classification\" : [\n",
    "        \"ag_news\", #AG news\n",
    "        \"sst2\",\n",
    "        \"hellaswag\", # HellaSwag\n",
    "        \"arc_easy\",\n",
    "        \"piqa\" #piqa\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244bdc9-b0de-406c-a823-48ee54513628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icl_variants = {\n",
    "    \"k_shot\": [0, 5, 10, 25],\n",
    "    \"decoding_strategy\": {\n",
    "        \"default\": {\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 64,\n",
    "            \"max_gen_toks\": 125,\n",
    "            \"do_sample\": True\n",
    "        },\n",
    "        \"greedy\": {\n",
    "            \"temperature\": 0,\n",
    "            \"do_sample\": False,\n",
    "            \"max_gen_toks\": 125\n",
    "        },\n",
    "        \"beam\": {\n",
    "            \"num_beams\": 5,\n",
    "            \"temperature\": 0,\n",
    "            \"do_sample\": False,\n",
    "            \"max_gen_toks\": 125\n",
    "        },\n",
    "        \"top_p\": {\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_gen_toks\": 125\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb5117-f74d-4fef-a347-bd423e5cf850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_gpu():\n",
    "    import os\n",
    "    os.system(\"\"\"\n",
    "    echo \"Cleaning up vLLM and CUDA contexts\"\n",
    "    pkill -f \"vllm\" || true\n",
    "    pkill -f \"engine_core\" || true\n",
    "    pkill -f \"torchrun\" || true\n",
    "    sleep 2\n",
    "    fuser -k /dev/nvidia* || true\n",
    "    \"\"\")\n",
    "clean_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d419d-4954-4ccd-8ae6-2164c260f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _result_path(model_id: str, task: str, n_shot: int, ds_name: str) -> str:\n",
    "    model_id = model_id.replace(\"/\", \"_\")\n",
    "    out_dir = os.path.join(\"results\",model_id , task)\n",
    "    return os.path.join(out_dir, f\"{model_id}_{n_shot}shot_{ds_name}.json\")\n",
    "\n",
    "def _result_exists_and_valid(path: str) -> bool:\n",
    "    if not os.path.exists(path):\n",
    "        return False\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "    metric_keys = (\"acc\", \"acc_norm\", \"em\", \"f1\",\n",
    "                   \"acc,none\", \"acc_norm,none\", \"em,none\", \"f1,none\")\n",
    "    return any(k in data for k in metric_keys)\n",
    "\n",
    "\n",
    "def _safe_save_json(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(\"w\", delete=False, dir=os.path.dirname(path), suffix=\".tmp\") as tmp:\n",
    "        json.dump(obj, tmp, indent=2)\n",
    "        tmp_path = tmp.name\n",
    "    os.replace(tmp_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efde59-6a33-479f-a02c-ad028dda5964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"hf\"\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "for model_id, model_args in gemma3_models.items():\n",
    "    if not model_id.endswith(\"it\"):continue\n",
    "    if isinstance(model_args, (list, tuple)):\n",
    "        model_args_str = \",\".join([str(part) for part in model_args if part])\n",
    "    else:\n",
    "        model_args_str = str(model_args)\n",
    "\n",
    "    for task_type, datasets in datasets_to_evaluate_on.items():\n",
    "        for task in datasets:\n",
    "            k_shot_variants = icl_variants[\"k_shot\"]\n",
    "            default_ds = icl_variants[\"decoding_strategy\"][\"default\"]\n",
    "            ds_name = \"default\"\n",
    "\n",
    "            best_k_shot = 10\n",
    "            best_k_perf = None\n",
    "\n",
    "            for n_shot in k_shot_variants:\n",
    "                out_path = _result_path(model_id, task, n_shot, ds_name)\n",
    "\n",
    "                if _result_exists_and_valid(out_path):\n",
    "                    print(f\"Skip (already done): {out_path}\")\n",
    "                    with open(out_path, \"r\") as f:\n",
    "                        metrics = json.load(f)\n",
    "                else:\n",
    "                    print(f\"\\nðŸ”¹ Evaluating model: {model_id} | task={task} | {n_shot}-shot | strategy=default\")\n",
    "                    results = evaluator.simple_evaluate(\n",
    "                        model=model_name,\n",
    "                        model_args=model_args_str,\n",
    "                        tasks=[task],\n",
    "                        num_fewshot=n_shot,\n",
    "                        gen_kwargs=default_ds,\n",
    "                        batch_size=\"auto\",\n",
    "                        device=\"auto\",\n",
    "                    )[\"results\"]\n",
    "\n",
    "                    metrics = results[task]\n",
    "                    _safe_save_json(out_path, metrics)\n",
    "\n",
    "                if task_type == \"classification\":\n",
    "                    metric_val = (\n",
    "                        metrics.get(\"acc_norm,none\")\n",
    "                        or metrics.get(\"acc_norm\")\n",
    "                        or metrics.get(\"acc\")\n",
    "                    )\n",
    "                else:  \n",
    "                    metric_val = (\n",
    "                        metrics.get(\"em,none\")\n",
    "                        or metrics.get(\"em\")\n",
    "                        or metrics.get(\"f1,none\")\n",
    "                        or metrics.get(\"f1\")\n",
    "                    )\n",
    "\n",
    "                if metric_val is not None and (best_k_perf is None or metric_val > best_k_perf):\n",
    "                    best_k_perf = metric_val\n",
    "                    best_k_shot = n_shot\n",
    "\n",
    "                clean_gpu()\n",
    "\n",
    "            print(f\"Best performance with {best_k_shot}-shot(s): {best_k_perf} | type={task_type} | task={task}\")\n",
    "\n",
    "            for decoding_strategy, ds_kwargs in icl_variants[\"decoding_strategy\"].items():\n",
    "                if decoding_strategy == \"default\":\n",
    "                    continue\n",
    "\n",
    "                out_path = _result_path(model_id, task, best_k_shot, decoding_strategy)\n",
    "\n",
    "                if _result_exists_and_valid(out_path):\n",
    "                    print(f\"Skip (already done): {out_path}\")\n",
    "                    with open(out_path, \"r\") as f:\n",
    "                        metrics = json.load(f)\n",
    "                else:\n",
    "                    print(f\"\\nðŸ”¹ Evaluating model: {model_id} | task={task} | {best_k_shot}-shot | strategy={decoding_strategy}\")\n",
    "                    results = evaluator.simple_evaluate(\n",
    "                        model=model_name,\n",
    "                        model_args=model_args_str,\n",
    "                        tasks=[task],\n",
    "                        num_fewshot=best_k_shot,\n",
    "                        gen_kwargs=ds_kwargs,\n",
    "                        batch_size=\"auto\",\n",
    "                        device=\"auto\",\n",
    "                    )[\"results\"]\n",
    "\n",
    "                    metrics = results[task]\n",
    "                    _safe_save_json(out_path, metrics)\n",
    "                    print(f\"Saved to {out_path}\")\n",
    "\n",
    "                clean_gpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (km_eval)",
   "language": "python",
   "name": "km_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
