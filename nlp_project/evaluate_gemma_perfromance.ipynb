{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abd4d78-f62c-4f05-aa56-2c205fa13a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# note this: set them when running\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\"\n",
    "num_gpus = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d49d53-45cb-4501-9739-0a65565e4981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-09 21:59:01 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import lm_eval\n",
    "from lm_eval import evaluator, tasks\n",
    "from lm_eval.utils import setup_logging\n",
    "setup_logging(\"DEBUG\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf4fdb9-9389-4cf9-bfd6-4b417a566c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_270m_pt_args = (\n",
    "    \"pretrained=google/gemma-3-270m,\"\n",
    "    \"tokenizer=google/gemma-3-270m,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_270m_it_args = (\n",
    "    \"pretrained=google/gemma-3-270m-it,\"\n",
    "    \"tokenizer=google/gemma-3-270m-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_1b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-1b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-1b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_1b_it_args = (\n",
    "    \"pretrained=google/gemma-3-1b-it,\"\n",
    "    \"tokenizer=google/gemma-3-1b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    " \n",
    ")\n",
    "\n",
    "gemma3_4b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-4b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-4b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_4b_it_args = (\n",
    "    \"pretrained=google/gemma-3-4b-it,\"\n",
    "    \"tokenizer=google/gemma-3-4b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "\n",
    ")\n",
    "\n",
    "gemma3_12b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-12b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-12b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_12b_it_args = (\n",
    "    \"pretrained=google/gemma-3-12b-it,\"\n",
    "    \"tokenizer=google/gemma-3-12b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_27b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-27b-pt,\"\n",
    "    \"tokenizer=google/gemma-3-27b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_27b_it_args = (\n",
    "    \"pretrained=google/gemma-3-27b-it,\"\n",
    "    \"tokenizer=google/gemma-3-27b-it,\"\n",
    "    \"dtype=bfloat16,\" \n",
    "    \"trust_remote_code=True\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472788c4-842d-4c4a-947e-846db64ff916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma3_models = {\n",
    "    \"google/gemma-3-270m-pt\" : gemma3_270m_pt_args,\n",
    "    \"google/gemma-3-270m-it\" : gemma3_270m_it_args,\n",
    "    \"google/gemma-3-1b-pt\" : gemma3_1b_pt_args,   \n",
    "    \"google/gemma-3-1b-it\" : gemma3_1b_it_args,   \n",
    "    \"google/gemma-3-4b-pt\" : gemma3_4b_pt_args,\n",
    "    \"google/gemma-3-4b-it\" : gemma3_4b_it_args,\n",
    "    \"google/gemma-3-12b-pt\" : gemma3_12b_pt_args,\n",
    "    \"google/gemma-3-12b-it\" : gemma3_12b_it_args,\n",
    "    \"google/gemma-3-27b-pt\" : gemma3_27b_pt_args,\n",
    "    \"google/gemma-3-27b-it\" : gemma3_27b_it_args\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f4b6ae-201a-4d55-9800-ee66547045c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma3_lora_adapters  = {\n",
    "    \"google/gemma-3-270m-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-1b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-4b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-12b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "    \"google/gemma-3-27b-it\" :  {\n",
    "        \"classification\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_CLS\",\n",
    "        \"qa\" : \"LINK_TO_HF_SAVED_LORA_ADAPTER_QA\"\n",
    "    },\n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603e4a8a-1e9b-4df1-89ca-d8f0ff26267e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_to_evaluate_on = {\n",
    "    \"question_answering\"  : [\n",
    "        \"squadv2\", # SQuAD \n",
    "        \"triviaqa\", \n",
    "        \"nq_open\", # natural queustions testing long context evaluation\n",
    "        \"boolq\", #boolq\n",
    "        \"social_iqa\", # social  QA \n",
    "    ],\n",
    "    \"classification\" : [\n",
    "        \"ag_news\", #AG news\n",
    "        \"sst2\",\n",
    "        \"hellaswag\", # HellaSwag\n",
    "        \"arc_easy\",\n",
    "        \"piqa\" #piqa\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f244bdc9-b0de-406c-a823-48ee54513628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icl_variants = {\n",
    "    \"k_shot\": [0, 5, 10, 25],\n",
    "    \"decoding_strategy\": {\n",
    "        \"default\": {\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 64,\n",
    "            \"max_gen_toks\": 125,\n",
    "            \"do_sample\": True\n",
    "        },\n",
    "        \"greedy\": {\n",
    "            \"temperature\": 0,\n",
    "            \"do_sample\": False,\n",
    "            \"max_gen_toks\": 125\n",
    "        },\n",
    "        \"beam\": {\n",
    "            \"num_beams\": 5,\n",
    "            \"temperature\": 0,\n",
    "            \"do_sample\": False,\n",
    "            \"max_gen_toks\": 125\n",
    "        },\n",
    "        \"top_p\": {\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_gen_toks\": 125\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9eb5117-f74d-4fef-a347-bd423e5cf850",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up vLLM and CUDA contexts\n"
     ]
    }
   ],
   "source": [
    "def clean_gpu():\n",
    "    import os\n",
    "    os.system(\"\"\"\n",
    "    echo \"Cleaning up vLLM and CUDA contexts\"\n",
    "    pkill -f \"vllm\" || true\n",
    "    pkill -f \"engine_core\" || true\n",
    "    pkill -f \"torchrun\" || true\n",
    "    sleep 2\n",
    "    fuser -k /dev/nvidia* || true\n",
    "    \"\"\")\n",
    "clean_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0efde59-6a33-479f-a02c-ad028dda5964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09:22:50:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-10-09:22:50:40 WARNING  [evaluator:214] generation_kwargs: {'temperature': 1, 'top_p': 0.95, 'top_k': 64, 'max_gen_toks': 125, 'do_sample': True} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!\n",
      "2025-10-09:22:50:40 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'google/gemma-3-270m-it', 'tokenizer': 'google/gemma-3-270m-it', 'dtype': 'bfloat16',\n",
      "        'trust_remote_code': True}\n",
      "2025-10-09:22:50:40 INFO     [models.huggingface:155] Device not specified\n",
      "2025-10-09:22:50:40 INFO     [models.huggingface:156] Cuda Available? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Evaluating model  : google/gemma-3-270m-it on task squad_qa with (0-shots), default strategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09:22:50:41 DEBUG    [models.huggingface:528] Using model type 'causal'\n",
      "2025-10-09:22:50:42 INFO     [models.huggingface:414] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "2025-10-09:22:50:43 INFO     [models.huggingface:254] Model type is 'gemma3_text', part of the Gemma family--a BOS token will be used as Gemma underperforms without it.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'squad_qa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_shot \u001b[38;5;129;01min\u001b[39;00m k_shot_variants:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ”¹ Evaluating model  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_shot\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-shots), default strategy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     results = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimple_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_args_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_fewshot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_shot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     27\u001b[39m     out_dir = os.path.join(\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m, model.replace(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m), task)\n\u001b[32m     28\u001b[39m     out_name = os.path.join(out_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.replace(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_shot\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mshot_default_ds.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/utils.py:456\u001b[39m, in \u001b[36mpositional_deprecated.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.ismethod(fn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    452\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWARNING: using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with positional arguments is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    453\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdeprecated and will be disallowed in a future version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    454\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlm-evaluation-harness!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    455\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/evaluator.py:283\u001b[39m, in \u001b[36msimple_evaluate\u001b[39m\u001b[34m(model, model_args, tasks, num_fewshot, batch_size, max_batch_size, device, use_cache, cache_requests, rewrite_requests_cache, delete_requests_cache, limit, samples, bootstrap_iters, check_integrity, write_out, log_samples, evaluation_tracker, system_instruction, apply_chat_template, fewshot_as_multiturn, gen_kwargs, task_manager, verbosity, predict_only, random_seed, numpy_random_seed, torch_random_seed, fewshot_random_seed, confirm_run_unsafe_code, metadata)\u001b[39m\n\u001b[32m    274\u001b[39m     metadata = (\n\u001b[32m    275\u001b[39m         simple_parse_args_string(model_args)\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_args, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    280\u001b[39m     ) | (metadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m    281\u001b[39m     task_manager = TaskManager(metadata=metadata)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m task_dict = \u001b[43mget_task_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# helper function to recursively apply config overrides to leaf subtasks, skipping their constituent groups.\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# (setting of num_fewshot ; bypassing metric calculation ; setting fewshot seed)\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_adjust_config\u001b[39m(task_dict):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/tasks/__init__.py:635\u001b[39m, in \u001b[36mget_task_dict\u001b[39m\u001b[34m(task_name_list, task_manager)\u001b[39m\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m task_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    633\u001b[39m         task_manager = TaskManager()\n\u001b[32m--> \u001b[39m\u001b[32m635\u001b[39m     task_name_from_string_dict = \u001b[43mtask_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task_or_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstring_task_name_list\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task_element \u001b[38;5;129;01min\u001b[39;00m others_task_name_list:\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_element, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/tasks/__init__.py:426\u001b[39m, in \u001b[36mTaskManager.load_task_or_group\u001b[39m\u001b[34m(self, task_list)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_list, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    423\u001b[39m     task_list = [task_list]\n\u001b[32m    425\u001b[39m all_loaded_tasks = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChainMap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_individual_task_or_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtask_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m )\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_loaded_tasks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/tasks/__init__.py:428\u001b[39m, in \u001b[36mTaskManager.load_task_or_group.<locals>.<lambda>\u001b[39m\u001b[34m(task)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_list, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    423\u001b[39m     task_list = [task_list]\n\u001b[32m    425\u001b[39m all_loaded_tasks = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    426\u001b[39m     collections.ChainMap(\n\u001b[32m    427\u001b[39m         *\u001b[38;5;28mmap\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m task: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_individual_task_or_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    429\u001b[39m             task_list,\n\u001b[32m    430\u001b[39m         )\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m )\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_loaded_tasks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/tasks/__init__.py:328\u001b[39m, in \u001b[36mTaskManager._load_individual_task_or_group\u001b[39m\u001b[34m(self, name_or_config, parent_name, update_config)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_task(task_config, task=name_or_config)\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     subtask_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tasklist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m subtask_list == -\u001b[32m1\u001b[39m:\n\u001b[32m    330\u001b[39m         group_config = \u001b[38;5;28mself\u001b[39m._get_config(name_or_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/km_eval/lib/python3.11/site-packages/lm_eval/tasks/__init__.py:238\u001b[39m, in \u001b[36mTaskManager._get_tasklist\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name_is_task(name):\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'squad_qa'"
     ]
    }
   ],
   "source": [
    "model_name = \"hf\"\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "for model in gemma3_models.keys():\n",
    "    if not model.endswith(\"it\"):\n",
    "        continue\n",
    "    model_args_str = \"\".join([part for part in gemma3_models[model] if part])\n",
    "    for task_type, datasets in datasets_to_evaluate_on.items():\n",
    "        for task in datasets:\n",
    "            k_shot_variants = icl_variants['k_shot']\n",
    "            default_ds = icl_variants['decoding_strategy']['default']\n",
    "            \n",
    "            best_k_shot  = None\n",
    "            best_k_perf = None\n",
    "            \n",
    "            for n_shot in k_shot_variants:\n",
    "                print(f\"\\nðŸ”¹ Evaluating model  : {model} on task {task} with ({n_shot}-shots), default strategy\")\n",
    "                results = evaluator.simple_evaluate(\n",
    "                    model=model_name,\n",
    "                    model_args=model_args_str,\n",
    "                    tasks=[task],\n",
    "                    num_fewshot=n_shot,\n",
    "                    gen_kwargs=default_ds,\n",
    "                    batch_size=\"auto\",\n",
    "                    device=\"auto\",  \n",
    "                )[\"results\"]\n",
    "                \n",
    "                out_dir = os.path.join(\"results\", model.replace(\"/\", \"_\"), task)\n",
    "                out_name = os.path.join(out_dir, f\"{model.replace('/', '_')}_{n_shot}shot_default_ds.json\")\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "                with open(out_name, \"w\") as f:\n",
    "                    json.dump(results[task], f, indent=2)\n",
    "                print(f\"Saved to {out_name}\")\n",
    "                \n",
    "                if task_type == \"classification\":\n",
    "                    if results[task]['acc_norm,none'] > best_k_perf:\n",
    "                        metric_val = (\n",
    "                            results_task.get(\"acc_norm,none\")\n",
    "                            or results_task.get(\"acc_norm\")\n",
    "                            or results_task.get(\"acc\")\n",
    "                            or float(\"-inf\")\n",
    "                        )\n",
    "                    elif results[task]['em,none'] > best_k_perf:\n",
    "                        metric_val = (\n",
    "                            results_task.get(\"em,none\")\n",
    "                            or results_task.get(\"em\")\n",
    "                            or results_task.get(\"f1,none\")\n",
    "                            or results_task.get(\"f1\")\n",
    "                            or float(\"-inf\")\n",
    "                        )\n",
    "                if metric_val > best_k_perf:\n",
    "                    best_k_perf = metric_val\n",
    "                    best_k_shot = n_shot\n",
    "                clean_gpu()\n",
    "            print(f\"Best performance with {best_k_shot}-shots, performance : {best_k_perf} on  {task_type}, task {task}\")\n",
    "            \n",
    "            for decoding_strategy, ds_kwargs in icl_variants['decoding_strategy'].items():\n",
    "                if decoding_strategy == \"default\": continue\n",
    "                print(f\"\\nðŸ”¹ Evaluating model  : {model} on task {task} with ({best_k_shot}-shots), decoding_strategy : {decoding_strategy}\")\n",
    "                results = evaluator.simple_evaluate(\n",
    "                    model=model_name,\n",
    "                    model_args=model_args_str,\n",
    "                    tasks=[task],\n",
    "                    num_fewshot=best_k_shot,\n",
    "                    gen_kwargs=ds_kwargs,\n",
    "                    batch_size=\"auto\",\n",
    "                    device=\"auto\",  \n",
    "                )[\"results\"]\n",
    "                \n",
    "                \n",
    "                out_dir = os.path.join(\"results\", model.replace(\"/\", \"_\"), task)\n",
    "                out_name = os.path.join(out_dir, f\"{model.replace('/', '_')}_{best_k_shot}shot_{decoding_strategy}_ds.json\")\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "                with open(out_name, \"w\") as f:\n",
    "                    json.dump(results[task], f, indent=2)\n",
    "                print(f\"Saved to {out_name}\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (km_eval)",
   "language": "python",
   "name": "km_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
