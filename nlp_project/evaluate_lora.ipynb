{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd4030-4f31-4412-a4c5-e1e9fe1eb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "num_gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be19ee-2e3f-447b-a4b7-1f5a47123a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unsloth\n",
    "import json\n",
    "from peft import PeftModel, PeftConfig\n",
    "from unsloth.chat_templates import get_chat_template \n",
    "import lm_eval\n",
    "from lm_eval import evaluator, tasks\n",
    "from lm_eval.utils import setup_logging\n",
    "import tempfile\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "setup_logging(\"INFO\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289cd4da-0dc5-4c6a-aa1b-2a4d9f52cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_270m_pt_args = (\n",
    "    \"pretrained=google/gemma-3-270m,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_270m_it_args = (\n",
    "    \"pretrained=google/gemma-3-270m-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_1b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-1b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_1b_it_args = (\n",
    "    \"pretrained=google/gemma-3-1b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_4b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-4b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_4b_it_args = (\n",
    "    \"pretrained=google/gemma-3-4b-it,\"\n",
    "    \"tokenizer=google/gemma-3-4b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "\n",
    ")\n",
    "\n",
    "gemma3_12b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-12b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_12b_it_args = (\n",
    "    \"pretrained=google/gemma-3-12b-it,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_27b_pt_args = (\n",
    "    \"pretrained=google/gemma-3-27b-pt,\"\n",
    "    \"dtype=bfloat16,\"\n",
    "    \"trust_remote_code=True\"\n",
    ")\n",
    "\n",
    "gemma3_27b_it_args = (\n",
    "    \"pretrained=google/gemma-3-27b-it,\"\n",
    "    \"dtype=bfloat16,\" \n",
    "    \"trust_remote_code=True\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8d198-b149-4baa-8de7-8b4eb5f577c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_lora_adapters  = {\n",
    "    \"google/gemma-3-270m-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-270m-it_ft_ag_news_v3\",\n",
    "        \"question_answering\" : \"Mhara/google_gemma-3-270m-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-1b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-1b-it_ft_ag_news_v2\",\n",
    "        \"question_answering\" : \"Mhara/google_gemma-3-1b-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-4b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-1b-it_ft_ag_news_v3\",\n",
    "        \"question_answering\" : \"Mhara/google_gemma-3-4b-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-12b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-12b-it_ft_ag_news\",\n",
    "        \"question_answering\" : \"Mhara/google_gemma-3-12b-it_ft_squad_v2\"\n",
    "    },\n",
    "    \"google/gemma-3-27b-it\" :  {\n",
    "        \"classification\" : \"Mhara/google_gemma-3-27b-it_ft_ag_news\",\n",
    "        \"question_answering\" : \"Mhara/google_gemma-3-27b-it_ft_squad_v2\"\n",
    "    },\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf45ac0-2166-48cc-b5d4-f4dc2e61ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adapter(base_model_id, adapter_id):\n",
    "    cfg = PeftConfig.from_pretrained(adapter_id)\n",
    "    base_id = cfg.base_model_name_or_path or base_model_id\n",
    "\n",
    "    _tok = AutoTokenizer.from_pretrained(base_id, use_fast=True, trust_remote_code=True)\n",
    "    base = AutoModelForCausalLM.from_pretrained(\n",
    "        base_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    _model = PeftModel.from_pretrained(base, adapter_id)\n",
    "    _model.eval()\n",
    "    tok = get_chat_template(_tok, chat_template=\"gemma3\")\n",
    "\n",
    "    return _model, _tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f29a6a-a273-4a17-92c5-047e802707da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _result_path(model_id, task, n_shot, ds_name, adapter_id=None):\n",
    "    adapter_suffix = f\"{adapter_id.split('/')[-1]}\" if adapter_id else \"\"\n",
    "    return f\"results/{adapter_suffix}/{task}_{n_shot}shot_{ds_name}.json\"\n",
    "\n",
    "def _result_exists_and_valid(path: str) -> bool:\n",
    "    if not os.path.exists(path):\n",
    "        return False\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "    metric_keys = (\"acc\", \"acc_norm\", \"em\", \"f1\",\n",
    "                   \"acc,none\", \"acc_norm,none\", \"em,none\", \"f1,none\")\n",
    "    return any(k in data for k in metric_keys)\n",
    "\n",
    "\n",
    "def _safe_save_json(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(\"w\", delete=False, dir=os.path.dirname(path), suffix=\".tmp\") as tmp:\n",
    "        json.dump(obj, tmp, indent=2)\n",
    "        tmp_path = tmp.name\n",
    "    os.replace(tmp_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee440b-ffbe-4e03-8d1a-e59a758b5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gpu():\n",
    "    import os\n",
    "    os.system(\"\"\"\n",
    "    echo \"Cleaning up vLLM and CUDA contexts\"\n",
    "    pkill -f \"vllm\" || true\n",
    "    pkill -f \"engine_core\" || true\n",
    "    pkill -f \"torchrun\" || true\n",
    "    sleep 2\n",
    "    fuser -k /dev/nvidia* || true\n",
    "    \"\"\")\n",
    "clean_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d769d-d055-4378-9f2f-992f6de53366",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_evaluate_on = {\n",
    "    \"question_answering\"  : [\n",
    "        \"squadv2\", # SQuAD\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac4e99-36de-4f20-b4c4-98bd438110b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_variants = {\n",
    "    \"k_shot\": [0,5],\n",
    "    \"decoding_strategy\": {\n",
    "        \"default\": {\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 64,\n",
    "            \"max_gen_toks\": 125,\n",
    "            \"do_sample\": True\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabe59c-fdcd-45e9-bb12-5127e44f9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_models_evaluation_values_full = {\n",
    "    \"google/gemma-3-270m-pt\" :{\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-270m-it\" :{\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-1b-pt\" :  {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]}, \n",
    "    \"google/gemma-3-1b-it\" :  {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]}, \n",
    "    \"google/gemma-3-4b-pt\" :  {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-4b-it\" :  {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-12b-pt\" : {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-12b-it\" : {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-27b-pt\" : {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "    \"google/gemma-3-27b-it\" : {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01cc30-7574-426b-8275-7afcff8c9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma3_models = {\n",
    "    \"google/gemma-3-270m-it\" : gemma3_270m_it_args,\n",
    "}\n",
    "gemma3_models_evaluation_values = {\n",
    "    \"google/gemma-3-270m-it\" : {\"n_shot\" : 0, \"ds_name\"  : \"default\", \"ds_kwargs\" :  icl_variants[\"decoding_strategy\"][\"default\"],\n",
    "                             \"adapter\" : gemma3_lora_adapters[\"google/gemma-3-270m-it\"][\"classification\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eea5f1-969b-4a52-87a4-3f5b53be5537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"hf\"\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "for model_id, model_args in gemma3_models.items():\n",
    "    if not model_id.endswith(\"it\"):\n",
    "        continue\n",
    "\n",
    "    if isinstance(model_args, (list, tuple)):\n",
    "        base_model_args_str = \",\".join([str(part) for part in model_args if part])\n",
    "    else:\n",
    "        base_model_args_str = str(model_args)\n",
    "\n",
    "    n_shot   = gemma3_models_evaluation_values[model_id][\"n_shot\"]\n",
    "    ds_kwargs = gemma3_models_evaluation_values[model_id][\"ds_kwargs\"] \n",
    "    ds_name  = \"default\"\n",
    "\n",
    "    adapter_map = gemma3_lora_adapters.get(model_id, {})\n",
    "\n",
    "    for task_type, datasets in datasets_to_evaluate_on.items():\n",
    "        adapter_id = gemma3_models_evaluation_values[model_id][\"adapter\"] \n",
    "\n",
    "        model_args_str = base_model_args_str\n",
    "        if adapter_id:\n",
    "            model_args_str += f\",peft={adapter_id}\"\n",
    "\n",
    "        for task in datasets:\n",
    "            for n_shot in icl_variants[\"k_shot\"]:\n",
    "                out_path = _result_path(model_id, task, n_shot, ds_name, adapter_id)\n",
    "                if _result_exists_and_valid(out_path):\n",
    "                    print(f\"Skip (already done): {out_path}\")\n",
    "                else:\n",
    "                    print(f\"\\nðŸ”¹ Evaluating model: {model_id} | tasks={task} | {n_shot}-shot | strategy=default\")\n",
    "                    results = evaluator.simple_evaluate(\n",
    "                        model=model_name,\n",
    "                        model_args=model_args_str,\n",
    "                        tasks=task,\n",
    "                        num_fewshot=n_shot,\n",
    "                        device=\"cuda:0\",\n",
    "                        batch_size=\"auto\",\n",
    "                    )[\"results\"]\n",
    "\n",
    "                    metrics = results[task]\n",
    "                    out_path = _result_path(model_id, task, n_shot, ds_name, adapter_id)\n",
    "                    _safe_save_json(out_path, metrics)\n",
    "                clean_gpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (km_eval)",
   "language": "python",
   "name": "km_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
